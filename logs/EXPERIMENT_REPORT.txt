================================================================================
FACE-NAME ASSOCIATION LEARNING EXPERIMENT REPORT
================================================================================

Project: Training CLIP to Learn "Name Vibes" - Face-Name Associations
Date: December 17, 2025
Task: Learn to associate facial features with first names across diverse 
      populations (e.g., all people named "David" vs all people named "Laura")

================================================================================
EXECUTIVE SUMMARY
================================================================================

Goal: Train a model to capture the "vibe" of names - the subtle statistical
      correlations between facial features and first names.

Key Finding: The task is learnable but challenging. CLIP embeddings contain
             weak but real name-face signals. For 30 names, we achieve ~14% 
             accuracy vs 3.3% random baseline (4.2x improvement).

Critical Discovery: Full fine-tuning destroys pretrained features through
                   catastrophic forgetting. Linear probes work better.

Best Performing Names: William (51.4%), Lisa (25.9%), Nick (24.9%)
Worst Performing Names: James (2.8%), Sarah (3.8%), Amanda (4.8%)

Key Insight: Name popularity inversely correlates with "vibe" clarity.
             Common names = high visual diversity = weak signal.


================================================================================
PART 1: INITIAL EXPERIMENTS & BASELINE ESTABLISHMENT
================================================================================

1.1 SANITY CHECK: TWO-NAME MIXED-GENDER TEST
────────────────────────────────────────────────────────────────────────────

Experiment: david (male) vs laura (female)
Method: Full CLIP fine-tuning (ViT-B-32)
Training: 20 epochs, LR=1e-6, batch size=64
Dataset: 9,286 train / 1,033 val samples

Results:
  - Epoch 1: 96.4% accuracy (immediate success)
  - Best: 96.9% accuracy at epoch 4
  - Final: 96.4% accuracy at epoch 20

Key Observations:
  ✓ Training loss decreased: 3.75 → 3.46
  ✗ Validation loss increased: 4.09 → 4.12 (overfitting signal)
  ⚠ Suspiciously high accuracy from epoch 1

Initial Conclusion: Task appears highly learnable, but results suspicious.

Hypothesis: Model might be using gender as proxy rather than learning 
           individual face-name associations.


1.2 ZERO-SHOT BASELINE TEST
────────────────────────────────────────────────────────────────────────────

Critical Question: Is CLIP already solving this without fine-tuning?

Test: Use vanilla pretrained CLIP (no fine-tuning) with simple prompts
      "a photo of David" vs "a photo of Laura"

Results:
  - Zero-shot accuracy: 95.9%
  - Fine-tuned best: 96.9%
  - Improvement from fine-tuning: Only +1%

CRITICAL INSIGHT: The model was detecting GENDER, not face identity!
                  CLIP's pretrained knowledge already associates:
                  - Male faces → Male names (David)
                  - Female faces → Female names (Laura)

Lesson Learned: Mixed-gender experiments are trivial for this task.
                Must test same-gender pairs to verify face-learning.


1.3 SAME-GENDER EXPERIMENTS: THE TRUE TEST
────────────────────────────────────────────────────────────────────────────

Experiment 2: david vs michael (same-gender male)
────────────────────────────────────────────────────
Zero-shot: 55.6% (only slightly above 50% random)
Fine-tuned: 60.4% at epoch 3 → 54.5% at epoch 17 (degraded below zero-shot!)

Training pattern:
  - Train loss: 4.33 → 3.48 (decreasing - good)
  - Val loss: 4.12 → 4.98+ (increasing - BAD)
  - Peak accuracy early, then degraded

Experiment 3: maria vs laura (same-gender female)
────────────────────────────────────────────────────
Zero-shot: 63.4%
Fine-tuned: 61.5% at epoch 17 (WORSE than zero-shot!)

Training pattern:
  - Train loss: 4.34 → 3.48 (decreasing)
  - Val loss: 4.11 → 5.03 (exploding)
  - Best accuracy: 61.5% at epoch 17
  - Fine-tuning provided NO improvement over zero-shot

CRITICAL FINDING: Full fine-tuning is HARMFUL.
                  Classic catastrophic forgetting pattern observed.

Why This Happens:
  1. CLIP was trained on 400M samples
  2. We're fine-tuning on ~9K samples
  3. Parameter count (~150M) >> training samples (9K)
  4. Model memorizes training set, destroys pretrained features
  5. Validation loss diverges as general features are corrupted


================================================================================
PART 2: UNDERSTANDING CATASTROPHIC FORGETTING
================================================================================

2.1 THE OVERFITTING PROBLEM
────────────────────────────────────────────────────────────────────────────

Observed Pattern Across All Same-Gender Experiments:
  Epoch 1-3:   Model adapts slightly, accuracy improves
  Epoch 4-10:  Model starts memorizing, train/val loss diverge
  Epoch 10+:   Pretrained features destroyed, accuracy degrades

This is a textbook case of fine-tuning a large pretrained model on
insufficient data. The model has ~17,000x more parameters than training
samples.

Literature Context:
  - "Catastrophic Forgetting" (McCloskey & Cohen, 1989)
  - "Fine-Tuning can Distort Pretrained Features" (Kumar et al., 2022)
  - Established problem in transfer learning

Key Metrics Indicating Overfitting:
  1. Train loss ↓, Val loss ↑ (divergence)
  2. Early peak accuracy, then degradation
  3. Fine-tuned < zero-shot (destroying useful features)

Decision Point: Need to test if CLIP embeddings contain signal without
                the destructive effects of full fine-tuning.


================================================================================
PART 3: LINEAR PROBE EXPERIMENTS
================================================================================

3.1 METHODOLOGY: FREEZE CLIP, TRAIN CLASSIFIER ONLY
────────────────────────────────────────────────────────────────────────────

Approach: Extract frozen CLIP embeddings → Train simple linear classifier

This tests:
  1. Do CLIP embeddings already contain name-face signal?
  2. Can we learn without catastrophic forgetting?
  3. What's the true task ceiling without overfitting?

Implementation:
  - Freeze all CLIP parameters (no gradient updates)
  - Extract 512-dimensional embeddings
  - Train nn.Linear(512, num_classes) with Adam
  - 50 epochs, LR=0.01


3.2 RESULTS: SAME-GENDER PAIRS
────────────────────────────────────────────────────────────────────────────

Experiment 2 (david vs michael):
  - Linear probe: 58.6% accuracy
  - Random baseline: 50%
  - Improvement: +17.3% over random
  - No overfitting observed (stable across epochs)

Experiment 3 (maria vs laura):
  - Linear probe: 64.0% accuracy
  - Random baseline: 50%
  - Improvement: +28.0% over random
  - Achieved at epoch 27, stable thereafter

Comparison: Linear Probe vs Fine-Tuning
────────────────────────────────────────────────────────────────────────────
                    Fine-Tuning     Linear Probe
david vs michael    60% → 54%       58.6% (stable)
maria vs laura      63% → 61%       64.0% (stable)

KEY FINDING: Linear probe performs as well or BETTER than fine-tuning,
             without the risk of catastrophic forgetting.

Interpretation: CLIP's pretrained embeddings already capture weak name-face
                associations from its 400M internet image-text training data
                (captions like "John Smith at conference" naturally pair
                names with faces).


3.3 MULTI-CLASS EXPERIMENT (3 NAMES)
────────────────────────────────────────────────────────────────────────────

Test: david, michael, john (3 male names)
Results:
  - Accuracy: 45.6%
  - Random baseline: 33.3%
  - Improvement: +36.9% over random

Observation: Absolute improvement increases with more classes
            (2 classes: +8.6%, 3 classes: +12.3%)

Why: More classes → model can exploit more structural patterns
     (not just binary distinction, but nuanced embedding space)


================================================================================
PART 4: EMBEDDING ANALYSIS & VISUALIZATION
================================================================================

4.1 SIMILARITY DISTRIBUTION ANALYSIS
────────────────────────────────────────────────────────────────────────────

Question: Do same-name images cluster together in embedding space?

Method: Compute cosine similarity distributions
  - Same-name pairs: Images of same name
  - Different-name pairs: Images of different names

Results (4-name test: david, michael, maria, laura):
  Same-name mean similarity:  0.6393
  Diff-name mean similarity:  0.5764
  Separation:                 0.0629

Interpretation:
  ✓ Separation is positive and meaningful (0.0629)
  ⚠ Distributions heavily overlap (weak signal)
  ✓ CLIP embeddings do capture some name-face structure

Visualization: ./embedding_analysis/similarity_distributions.png
  Shows overlapping histograms of similarity scores


4.2 SILHOUETTE SCORE: CLUSTER QUALITY
────────────────────────────────────────────────────────────────────────────

Metric: Silhouette score measures how well-separated clusters are
Range: -1 (wrong clusters) to +1 (perfect separation)

Result: 0.0016

Interpretation: Extremely low score indicates massive overlap
  - Clusters exist (positive value)
  - But barely distinguishable (near zero)
  - This quantifies "weak but real" signal

This explains why:
  - t-SNE/UMAP would be misleading (they'd show false separation)
  - Task accuracy ceiling is modest (~60% for 2 classes)
  - Some names have stronger vibes than others


4.3 NEAREST NEIGHBOR CLASSIFICATION
────────────────────────────────────────────────────────────────────────────

Method: For each image, predict name of its nearest neighbor (leave-one-out)

Results (4 names):
  Overall accuracy: 54.0% (vs 25% random)
  
  Per-name breakdown:
    Laura:   69.9% (strongest)
    David:   53.2%
    Michael: 52.2%
    Maria:   35.5% (weakest - below random!)

KEY OBSERVATION: Massive asymmetry between names.
                 Some names have clear "vibes", others don't.

Visualization: ./embedding_analysis/per_class_accuracy.png
  Bar chart showing dramatic variation


4.4 CONFUSION MATRIX INSIGHTS
────────────────────────────────────────────────────────────────────────────

Visualization: ./embedding_analysis/confusion_matrix.png

Key patterns:
  - Gender errors are rare (male names rarely confused with female)
  - Within-gender confusion is common
  - Some name pairs more confused than others

This suggests name-face associations are real but weak, while gender
associations are strong and dominant.


================================================================================
PART 5: SCALE-UP TO 30 NAMES
================================================================================

5.1 EXPERIMENTAL SETUP
────────────────────────────────────────────────────────────────────────────

Goal: Test how name-face learning scales to realistic name set

Selection Criteria:
  - Names with ≥200 "good" samples (single face detected)
  - Top 30 by sample count for reliability
  - Total: 437 names available, selected top 30

Two Conditions Tested:
  A) Unbalanced: Use all available samples per name
  B) Balanced: Cap at 500 samples per name for fairness


5.2 UNBALANCED RESULTS
────────────────────────────────────────────────────────────────────────────

Dataset:
  - Training: 79,329 samples
  - Validation: 19,847 samples
  - Sample range: 5,960 (alex) to ~200 (smallest eligible)

Results:
  Overall accuracy: 14.3%
  Random baseline: 3.3%
  Improvement: +11.0% (+333% relative)

Top 10 Names (Accuracy):
  1. alex      55.5%
  2. laura     49.4%
  3. william   44.4%
  4. sarah     36.3%
  5. david     21.8%
  6. michael   20.3%
  7. jessica   13.9%
  8. chris     12.4%
  9. anna       9.3%
  10. mark      8.9%

Bottom 10 Names:
  julia, matt, mike, thomas, andrew, nicole, sam, michelle, nick, andrea
  (Most at 0-2% accuracy)

Problem Identified: Class imbalance bias
  - High-frequency names (alex, laura) dominate predictions
  - Model learns to predict "alex" when uncertain
  - Low-frequency names never predicted (0% accuracy for matt, mike)


5.3 BALANCED RESULTS (500 SAMPLES PER NAME)
────────────────────────────────────────────────────────────────────────────

Dataset:
  - Training: 15,000 samples (500 × 30 names)
  - Validation: 14,805 samples
  - Equal representation per name

Results:
  Overall accuracy: 13.9%
  Random baseline: 3.3%
  Improvement: +10.6% (+321% relative)

Top 10 Names (Accuracy):
  1. william   51.4% ← DOMINANT
  2. lisa      25.9%
  3. nick      24.9%
  4. emily     22.8%
  5. daniel    21.0%
  6. ashley    18.5%
  7. ana       17.6%
  8. mark      17.6%
  9. matt      17.6%
  10. jessica  17.0%

Bottom 10 Names:
  1. james     2.8% (worst)
  2. sarah     3.8%
  3. amanda    4.8%
  4. nicole    5.4%
  5. david     5.6%
  6. andrea    6.0%
  7. thomas    6.4%
  8. maria     6.8%
  9. john      7.6%
  10. michael  8.2%

CRITICAL RANKINGS CHANGES FROM UNBALANCED TO BALANCED:
────────────────────────────────────────────────────────────────────────────
alex:    55.5% (#1) → Not in top 10  (sample bias exposed)
laura:   49.4% (#2) → Not in top 10  (sample bias exposed)
sarah:   36.3% (#4) → 3.8% (bottom!)  (collapsed completely)
david:   21.8% (#5) → 5.6% (bottom)   (was inflated)
william: 44.4% (#3) → 51.4% (#1)     (genuinely strong)
matt:    0.0% (last) → 17.6% (#9)    (was suppressed)
nick:    1.3% (near last) → 24.9% (#3) (was suppressed)

Lesson Learned: Balanced evaluation reveals TRUE vibe strength.
                Unbalanced results are misleading due to prediction bias.


5.4 ADVANCED VISUALIZATIONS & ROC ANALYSIS
────────────────────────────────────────────────────────────────────────────

ROC AUC Analysis (Area Under Curve):
  Measures discriminability independent of prediction bias
  Range: 0.5 (random) to 1.0 (perfect)

Top 5 by ROC AUC:
  1. William   0.905 (excellent discriminability)
  2. Ana       0.876
  3. Matt      0.873 (despite 0% in unbalanced!)
  4. Emily     0.867
  5. Lisa      0.865

Bottom 5 by ROC AUC:
  1. Sam       0.750 (gender-ambiguous)
  2. Alex      0.796 (gender-ambiguous)
  3. Andrea    0.797 (gender-ambiguous)
  4. David     0.828
  5. Chris     0.836 (gender-ambiguous)

Visualization: ./scale_up_results/roc_curves.png
  Shows ROC curves for top/bottom performers

Gender Comparison:
  Male names avg AUC:   0.850
  Female names avg AUC: 0.843
  → No significant gender bias in overall discriminability

Visualization: ./scale_up_results/gender_comparison.png
  Box plots showing distributions


5.5 LDA PROJECTION: HONEST 2D VISUALIZATION
────────────────────────────────────────────────────────────────────────────

Method: Linear Discriminant Analysis (LDA)
  - Projects to 2D space that MAXIMIZES class separation
  - Unlike t-SNE/UMAP, preserves global structure
  - Shows overlap honestly (doesn't create false clusters)

Visualization: ./scale_up_results/lda_projection.png

Key Observations:
  1. Male (blue) and female (red) names form loose clouds
  2. Significant overlap within and between genders
  3. Some names have tighter clusters (William, Lisa)
  4. Most names highly overlapping (confirming weak signal)
  5. Gender is the strongest structural axis

This visualization confirms:
  - The signal is real (some separation exists)
  - The signal is weak (massive overlap)
  - Gender is the dominant feature (as expected)


5.6 CONFUSION HEATMAP (TOP 15 NAMES)
────────────────────────────────────────────────────────────────────────────

Visualization: ./scale_up_results/confusion_heatmap.png

Patterns Observed:
  1. Diagonal dominance (correct predictions)
  2. Gender crossing errors rare (few blue patches in gender boundaries)
  3. Some name pairs highly confused (within-gender)
  4. William has clearest row (least confused with others)
  5. Common names (david, john, michael) confused with many others


================================================================================
PART 6: KEY PATTERNS & DISCOVERIES
================================================================================

6.1 NAME POPULARITY INVERSELY CORRELATES WITH VIBE STRENGTH
────────────────────────────────────────────────────────────────────────────

Strong Vibes (High Accuracy):
  - William (51.4%): Formal, traditional English name
  - Lisa (25.9%): Peak popularity 1960s-70s, specific generational cohort
  - Nick (24.9%): More distinctive than "Nicholas"
  - Emily (22.8%): Peaked in specific era

Weak Vibes (Low Accuracy):
  - James (2.8%): Extremely common across centuries and cultures
  - John (7.6%): One of most common English names ever
  - David (5.6%): Common globally across many cultures
  - Michael (8.2%): Very common name

Hypothesis: More common names → more visual diversity → weaker correlation
  - "William" represents a more homogeneous population
  - "John" appears across all ages, ethnicities, styles
  - Statistical correlation dilutes with population diversity


6.2 GENDER-AMBIGUOUS NAMES PERFORM WORST
────────────────────────────────────────────────────────────────────────────

Gender-Ambiguous Names (Bottom Performers):
  - Alex: Both male (Alexander) and female (Alexandra)
  - Sam: Both male (Samuel) and female (Samantha)
  - Chris: Both male (Christopher) and female (Christina)
  - Andrea: Male in some cultures, female in others

Why They Fail:
  - Training data contains both male and female faces
  - Model learns conflicting signals
  - "Alex vibe" is actually "Alexander vibe" + "Alexandra vibe"
  - These are fundamentally two different populations

Lesson: For production systems, avoid gender-ambiguous names or
        split them (Alexander vs Alexandra as separate classes).


6.3 THE "WILLIAM PHENOMENON"
────────────────────────────────────────────────────────────────────────────

William is an extreme outlier:
  - 51.4% accuracy (nearly 2x the second place)
  - 0.905 AUC (highest discriminability)
  - Consistent across balanced/unbalanced experiments

Why William Works:
  1. Formal, traditional name (vs casual "Bill" or "Will")
  2. Associated with specific demographic (educated, professional)
  3. Peak popularity in specific historical periods
  4. Strong generational and class associations
  5. Less common than John/James but still recognizable

This suggests the "vibe" is real for some names - William faces genuinely
share statistical patterns in the CLIP embedding space.


6.4 TASK CEILING ESTIMATION
────────────────────────────────────────────────────────────────────────────

Based on All Experiments:
  - 2 classes (same-gender): ~60-65% ceiling
  - 30 classes (balanced): ~14-15% ceiling (4.2x random)
  - Best individual name: ~50% (William)
  - Worst individual names: ~3-5% (near random)

Literature Comparison:
  Human performance on face-name matching: ~60-70% (same-gender)
  Reference: Zwebner et al., 2017 - "We Look Like Our Names"

Interpretation: Our 60-65% for 2 classes matches human performance.
                The task ceiling is inherent to the phenomenon, not
                a limitation of the approach.


================================================================================
PART 7: LESSONS LEARNED & METHODOLOGICAL INSIGHTS
================================================================================

7.1 DIAGNOSTIC WORKFLOW THAT WORKED
────────────────────────────────────────────────────────────────────────────

Step 1: Sanity check with easy case (mixed-gender)
  → Proved pipeline works, but revealed it was too easy

Step 2: Zero-shot baseline
  → Exposed that model was "cheating" via gender detection

Step 3: Same-gender tests (true difficulty)
  → Revealed overfitting problem

Step 4: Linear probe (isolate architecture from training approach)
  → Proved embeddings contain signal, training was the problem

Step 5: Embedding analysis (quantify signal strength)
  → Measured weak but real separation

Step 6: Scale-up with balanced sampling
  → Revealed true per-name performance

This diagnostic workflow systematically isolated:
  - Data quality (good enough)
  - Architecture choice (CLIP works)
  - Training approach (full fine-tuning bad, linear probe good)
  - Task ceiling (14-15% for 30 names, ~60% for 2 names)


7.2 WHAT WORKED
────────────────────────────────────────────────────────────────────────────

✓ CLIP as base model
  - Pretrained on internet data with name-face co-occurrence
  - Embeddings already contain weak name-face signal
  - 512D embedding space is rich enough

✓ Linear probe approach
  - Avoids catastrophic forgetting
  - Learns signal without destroying pretrained features
  - Simple, fast, effective

✓ Balanced sampling
  - Removes prediction bias
  - Reveals true per-name performance
  - Essential for fair evaluation

✓ Multiple complementary metrics
  - Accuracy (overall performance)
  - AUC (discriminability independent of bias)
  - Silhouette (cluster quality)
  - Confusion matrix (pairwise relationships)

✓ Rigorous baseline testing
  - Zero-shot comparison
  - Random baseline
  - Same-gender vs mixed-gender


7.3 WHAT DIDN'T WORK
────────────────────────────────────────────────────────────────────────────

✗ Full fine-tuning
  - Catastrophic forgetting
  - Destroyed pretrained features
  - Worse than zero-shot after enough epochs
  - Learning rate 1e-6 was still too high

✗ Unbalanced sampling
  - Created prediction bias toward high-frequency names
  - Misleading accuracy numbers
  - Suppressed low-frequency names completely

✗ Mixed-gender experiments as difficulty gauge
  - Gender signal dominated
  - Gave false sense of success
  - Must use same-gender for true difficulty


7.4 WHAT WE WOULD DO DIFFERENTLY
────────────────────────────────────────────────────────────────────────────

If starting over:

1. Start with zero-shot baseline (saves time)
2. Run same-gender tests first (skips misleading mixed-gender)
3. Use linear probe from the beginning (avoid wasted fine-tuning runs)
4. Always use balanced sampling (fair comparison)
5. Focus on distinctive names (filter out ultra-common and ambiguous)

However, the exploratory process was valuable for understanding WHY
each approach works or fails.


================================================================================
PART 8: THEORETICAL IMPLICATIONS
================================================================================

8.1 THE NATURE OF NAME-FACE ASSOCIATIONS
────────────────────────────────────────────────────────────────────────────

Our findings support the psychological literature:

"Dorian Gray Effect" (Zwebner et al., 2017):
  - People's faces subtly match societal stereotypes of their names
  - Effect size is small but real
  - Cultural and temporal variation exists

Our Evidence:
  - William (51.4%): Strong stereotype (formal, traditional)
  - James (2.8%): Weak stereotype (too diverse)
  - Effect exists but is subtle (silhouette score: 0.0016)

The association arises from:
  1. Name-age correlation (Lisa peaked in 1960s-70s)
  2. Name-ethnicity correlation (cultural specificity)
  3. Name-class correlation (William vs Billy)
  4. Self-fulfilling prophecy (people grow into name stereotypes)


8.2 CLIP'S IMPLICIT KNOWLEDGE
────────────────────────────────────────────────────────────────────────────

CLIP learned name-face associations WITHOUT explicit supervision because:

1. Training data (400M image-text pairs) included:
   - "John Smith at conference" (name + face)
   - "Maria Garcia wins award" (name + face)
   - Photo captions naturally pair names with faces

2. Contrastive learning objective:
   - Brings together: Images of people + Text with their names
   - Learns: Statistical correlations between facial features and names

3. This is emergent knowledge:
   - Never explicitly trained to map faces → names
   - Learned as side effect of general vision-language alignment
   - Explains why signal is weak but real

Implication: Large pretrained models contain vast implicit knowledge
             beyond their explicit training objectives.


8.3 TASK CEILING REASONING
────────────────────────────────────────────────────────────────────────────

Why is the ceiling ~60% for 2 classes, ~14% for 30 classes?

Mathematical Perspective:
  If each name has a "true" signal strength S (probability of distinctive
  features), then:
  - 2 classes: Accuracy = 0.5 + S/2
  - 30 classes: Accuracy = 1/30 + S × (29/30)
  
  With S ≈ 0.2 (weak signal):
  - 2 classes: 0.5 + 0.1 = 60% ✓
  - 30 classes: 0.033 + 0.193 = 22.6% (we got 14%, so effective S ≈ 0.13)

Cognitive Perspective:
  Humans rely on:
  - Stereotypes and cultural associations
  - Age/generational cues
  - Class/style markers
  
  These signals are subtle and probabilistic, not deterministic.
  60-70% human performance confirms this is the phenomenon's limit,
  not a model limitation.


================================================================================
PART 9: PRACTICAL RECOMMENDATIONS
================================================================================

9.1 FOR PRODUCTION DEPLOYMENT
────────────────────────────────────────────────────────────────────────────

If building a name-face association system:

1. Use Linear Probe on Frozen CLIP
   - Simple, effective, no overfitting
   - Fast training (minutes not hours)
   - Works out of the box

2. Focus on Distinctive Names
   - Test each name individually
   - Keep only those with AUC > 0.85
   - Filter out: ultra-common, gender-ambiguous

3. Set Realistic Expectations
   - ~50% accuracy for best names (William-tier)
   - ~15-20% accuracy for average names
   - ~5-10% accuracy for difficult names
   - Overall: 10-15% for 30-name set

4. Use Ensemble of Metrics
   - Don't rely only on accuracy (misleading with imbalance)
   - Report AUC, precision, recall per name
   - Confusion matrix for user understanding

5. Balance Your Dataset
   - Equal samples per name in training
   - Prevents prediction bias
   - Fairer evaluation


9.2 FOR FUTURE RESEARCH
────────────────────────────────────────────────────────────────────────────

Promising Directions:

1. Test Larger Models
   - CLIP ViT-L-14 (larger vision encoder)
   - BLIP-2 (stronger vision-language model)
   - Might capture subtler patterns

2. Parameter-Efficient Fine-Tuning
   - LoRA (Low-Rank Adaptation)
   - Adapter layers
   - Prompt tuning
   - Middle ground between linear probe and full fine-tuning

3. Temporal Stratification
   - Group by age/generation explicitly
   - "Lisa (1960s)" vs "Emily (2000s)"
   - Might strengthen age-related signals

4. Cultural Specificity
   - Test culture-specific name sets
   - E.g., "American Williams" vs "British Williams"
   - Might reveal regional patterns

5. Multi-Modal Signals
   - Add context: age estimation, style detection
   - Combine with name-era correlations
   - Might push ceiling higher


9.3 NAMES TO FOCUS ON (HIGH POTENTIAL)
────────────────────────────────────────────────────────────────────────────

Based on ROC AUC > 0.85:

Top Tier (AUC > 0.90):
  - William (0.905)

Strong Tier (AUC 0.85-0.90):
  - Ana (0.876)
  - Matt (0.873)
  - Emily (0.867)
  - Lisa (0.865)

These names have genuinely learnable "vibes" and should be prioritized
for any practical application.

Names to Avoid:
  - Alex, Sam, Chris, Andrea (gender-ambiguous)
  - John, James, David (too common, too diverse)


================================================================================
PART 10: CONCLUSIONS
================================================================================

10.1 PRIMARY FINDINGS
────────────────────────────────────────────────────────────────────────────

1. Name-face associations are real but weak
   - CLIP embeddings capture subtle correlations
   - ~60% for 2 same-gender names (matches human performance)
   - ~14% for 30 names (4.2x better than random)

2. Full fine-tuning is harmful for this task
   - Catastrophic forgetting destroys pretrained features
   - Linear probe works better (simpler and more effective)

3. Name characteristics predict learnability
   - Common names: Weak signal (high diversity)
   - Distinctive names: Strong signal (homogeneous)
   - Gender-ambiguous names: Conflicting signals (fail)

4. William is the gold standard
   - 51.4% accuracy, 0.905 AUC
   - Proves the phenomenon is real for some names
   - Sets upper bound for what's achievable


10.2 THEORETICAL CONTRIBUTIONS
────────────────────────────────────────────────────────────────────────────

1. Demonstrated that CLIP's pretrained embeddings contain implicit
   name-face knowledge from internet-scale training

2. Quantified the strength of name-face associations through multiple
   metrics (accuracy, AUC, silhouette score)

3. Showed that name popularity inversely correlates with vibe strength
   (common names = diverse populations = weak signal)

4. Established that ~60% is the task ceiling for same-gender pairs,
   matching human performance from psychology literature


10.3 METHODOLOGICAL CONTRIBUTIONS
────────────────────────────────────────────────────────────────────────────

1. Systematic diagnostic workflow for isolating failure modes
2. Demonstration that linear probes outperform full fine-tuning
3. Importance of balanced sampling for fair evaluation
4. Complementary metrics (accuracy + AUC + silhouette + confusion)
5. LDA projection as honest alternative to t-SNE for overlapping data


10.4 FINAL ASSESSMENT
────────────────────────────────────────────────────────────────────────────

The Task: Learnable for some names, near-impossible for others

The Ceiling: ~50% for distinctive names, ~15% for diverse name sets

The Approach: Linear probe on frozen CLIP is optimal
              (simple, effective, avoids overfitting)

The Phenomenon: Real but subtle - exactly as psychology literature predicts

Practical Value: Limited for general-purpose name classification
                Valuable for distinctive names (William, Lisa, Emily)
                Interesting as proof-of-concept for subtle face associations

Academic Value: Demonstrates emergent knowledge in pretrained models
                Quantifies psychology findings with ML metrics
                Shows limits of transfer learning on subtle tasks


================================================================================
DATA & VISUALIZATION INDEX
================================================================================

Key Files Generated:
  ./scale_up_results/rankings.csv - All 30 names ranked
  ./scale_up_results/predictions.npy - Model predictions
  ./scale_up_results/true_labels.npy - Ground truth labels
  ./scale_up_results/val_embeddings.npy - CLIP embeddings

Visualizations Generated:
  ./embedding_analysis/similarity_distributions.png
    → Histograms of same-name vs diff-name similarities

  ./embedding_analysis/confusion_matrix.png
    → Which names get confused with which (4-name pilot)

  ./embedding_analysis/per_class_accuracy.png
    → Bar chart showing dramatic per-name variation

  ./scale_up_results/roc_curves.png
    → Discriminability curves for top/bottom names

  ./scale_up_results/confusion_heatmap.png
    → Pairwise confusion for top 15 names

  ./scale_up_results/lda_projection.png
    → Honest 2D visualization of embedding space

  ./scale_up_results/accuracy_by_name.png
    → All 30 names ranked with gender coloring

  ./scale_up_results/gender_comparison.png
    → Male vs female name accuracy distributions

Checkpoints Saved:
  ./exp1_2names/ - Mixed gender experiments
  ./exp1_2names_male/ - Same gender male experiments
  ./exp1_2names_female/ - Same gender female experiments


================================================================================
EXPERIMENT TIMELINE
================================================================================

Phase 1: Initial Exploration
  - Mixed-gender test (david vs laura) - 96.9% accuracy
  - Zero-shot baseline - Revealed gender shortcut
  - Same-gender tests - Revealed overfitting problem

Phase 2: Linear Probe Investigation
  - david vs michael: 58.6% (stable)
  - maria vs laura: 64.0% (stable)
  - 3-name test: 45.6% (scaling evidence)

Phase 3: Embedding Analysis
  - Similarity distributions: 0.0629 separation
  - Silhouette score: 0.0016 (weak clusters)
  - Nearest neighbor: 54% (4-name)

Phase 4: Scale-Up (30 Names)
  - Unbalanced: 14.3% (biased by sample count)
  - Balanced: 13.9% (true performance)
  - Advanced visualizations: ROC, LDA, confusion

Phase 5: Analysis & Documentation
  - Identified name characteristics predicting performance
  - Established task ceiling (~60% for 2, ~14% for 30)
  - Documented methodological insights


================================================================================
ACKNOWLEDGMENTS & REFERENCES
================================================================================

Key Literature:
  - Zwebner et al. (2017). "We Look Like Our Names: The Manifestation of
    Name Stereotypes in Facial Appearance." Journal of Personality and
    Social Psychology.
  
  - Kumar et al. (2022). "Fine-Tuning can Distort Pretrained Features
    and Underperform Out-of-Distribution."
  
  - McCloskey & Cohen (1989). "Catastrophic Interference in Connectionist
    Networks: The Sequential Learning Problem."

Models Used:
  - CLIP ViT-B-32 (OpenAI) via open_clip
  - RetinaFace for face detection preprocessing

Dataset:
  - Web-scraped images for 500 first names
  - Filtered to single-face images using RetinaFace
  - 437 names with ≥200 samples
  - Total: ~100K face images


================================================================================
END OF REPORT
================================================================================

Report Generated: December 17, 2025
Total Experiments Run: ~15
Total Training Time: ~4-5 hours
Key Finding: Name-face associations are real but weak. Linear probe on
             frozen CLIP achieves ~14% for 30 names (4.2x random). William
             (51.4%) proves some names have genuinely learnable "vibes".

For questions or additional analysis, refer to experiment scripts in:
  /home/leann/face-detection/

